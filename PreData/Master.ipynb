{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Country          Region  Happiness Rank  Happiness Score  \\\n0      Denmark  Western Europe               1            7.526   \n1  Switzerland  Western Europe               2            7.509   \n2      Iceland  Western Europe               3            7.501   \n3       Norway  Western Europe               4            7.498   \n4      Finland  Western Europe               5            7.413   \n\n   Lower Confidence Interval  Upper Confidence Interval  \\\n0                      7.460                      7.592   \n1                      7.428                      7.590   \n2                      7.333                      7.669   \n3                      7.421                      7.575   \n4                      7.351                      7.475   \n\n   Economy (GDP per Capita)   Family  Health (Life Expectancy)  Freedom  \\\n0                   1.44178  1.16374                   0.79504  0.57941   \n1                   1.52733  1.14524                   0.86303  0.58557   \n2                   1.42666  1.18326                   0.86733  0.56624   \n3                   1.57744  1.12690                   0.79579  0.59609   \n4                   1.40598  1.13464                   0.81091  0.57104   \n\n   Trust (Government Corruption)  Generosity  Dystopia Residual  \n0                        0.44453     0.36171            2.73939  \n1                        0.41203     0.28083            2.69463  \n2                        0.14975     0.47678            2.83137  \n3                        0.35776     0.37895            2.66465  \n4                        0.41004     0.25492            2.82596  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Region</th>\n      <th>Happiness Rank</th>\n      <th>Happiness Score</th>\n      <th>Lower Confidence Interval</th>\n      <th>Upper Confidence Interval</th>\n      <th>Economy (GDP per Capita)</th>\n      <th>Family</th>\n      <th>Health (Life Expectancy)</th>\n      <th>Freedom</th>\n      <th>Trust (Government Corruption)</th>\n      <th>Generosity</th>\n      <th>Dystopia Residual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Denmark</td>\n      <td>Western Europe</td>\n      <td>1</td>\n      <td>7.526</td>\n      <td>7.460</td>\n      <td>7.592</td>\n      <td>1.44178</td>\n      <td>1.16374</td>\n      <td>0.79504</td>\n      <td>0.57941</td>\n      <td>0.44453</td>\n      <td>0.36171</td>\n      <td>2.73939</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Switzerland</td>\n      <td>Western Europe</td>\n      <td>2</td>\n      <td>7.509</td>\n      <td>7.428</td>\n      <td>7.590</td>\n      <td>1.52733</td>\n      <td>1.14524</td>\n      <td>0.86303</td>\n      <td>0.58557</td>\n      <td>0.41203</td>\n      <td>0.28083</td>\n      <td>2.69463</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Iceland</td>\n      <td>Western Europe</td>\n      <td>3</td>\n      <td>7.501</td>\n      <td>7.333</td>\n      <td>7.669</td>\n      <td>1.42666</td>\n      <td>1.18326</td>\n      <td>0.86733</td>\n      <td>0.56624</td>\n      <td>0.14975</td>\n      <td>0.47678</td>\n      <td>2.83137</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Norway</td>\n      <td>Western Europe</td>\n      <td>4</td>\n      <td>7.498</td>\n      <td>7.421</td>\n      <td>7.575</td>\n      <td>1.57744</td>\n      <td>1.12690</td>\n      <td>0.79579</td>\n      <td>0.59609</td>\n      <td>0.35776</td>\n      <td>0.37895</td>\n      <td>2.66465</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Finland</td>\n      <td>Western Europe</td>\n      <td>5</td>\n      <td>7.413</td>\n      <td>7.351</td>\n      <td>7.475</td>\n      <td>1.40598</td>\n      <td>1.13464</td>\n      <td>0.81091</td>\n      <td>0.57104</td>\n      <td>0.41004</td>\n      <td>0.25492</td>\n      <td>2.82596</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 810
    }
   ],
   "source": [
    "########Begin Pre Processing the Happiness Scores CSV#########\n",
    "# Read in the Happiness CSV files\n",
    "happy_16 = pd.read_csv('2016.csv')\n",
    "happy_18 = pd.read_csv('2018.csv')\n",
    "\n",
    "# Print top of table as example\n",
    "happy_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Country          Region  Happiness Score\n0      Finland  Western Europe            7.632\n1       Norway  Western Europe            7.594\n2      Denmark  Western Europe            7.555\n3      Iceland  Western Europe            7.495\n4  Switzerland  Western Europe            7.487",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Region</th>\n      <th>Happiness Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Finland</td>\n      <td>Western Europe</td>\n      <td>7.632</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Norway</td>\n      <td>Western Europe</td>\n      <td>7.594</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Denmark</td>\n      <td>Western Europe</td>\n      <td>7.555</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Iceland</td>\n      <td>Western Europe</td>\n      <td>7.495</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Switzerland</td>\n      <td>Western Europe</td>\n      <td>7.487</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 811
    }
   ],
   "source": [
    "# Create new tables out of the relvant colums from the database\n",
    "Happy16 =  happy_16[['Country', 'Region', 'Happiness Score']].copy() # Create new table with relevant features for 2016\n",
    "Happy18 =  happy_18[['Country or region', 'Score']].copy() # Create new table with relevant features for 2018\n",
    "Happy18.columns = ['Country', 'Happiness Score'] # Change column names to make them consistent\n",
    "Happy18 = pd.merge(Happy18, Happy16[['Country', 'Region']], on=['Country'], how='left') # Merge the regional information from 16 to 18\n",
    "Happy18 = Happy18[['Country', 'Region', 'Happiness Score']] # Reorder columns\n",
    "Happy18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'Lesotho', 'Trinidad & Tobago', 'Mozambique', 'Northern Cyprus', 'Central African Republic'}\n{'Southeastern Asia', 'Sub-Saharan Africa', 'Central and Eastern Europe', 'Western Europe', 'Australia and New Zealand', 'North America', 'Latin America and Caribbean', 'Middle East and Northern Africa', 'Eastern Asia', 'Southern Asia'}\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Country            0\nRegion             0\nHappiness Score    0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 812
    }
   ],
   "source": [
    "# Find and clean missing values for Region\n",
    "print(set(Happy18['Country']) - set(Happy16['Country'])) # Get Set of missing values\n",
    "print(set(Happy16['Region'])) # Get set of possible regions\n",
    "\n",
    "# Match different spellings of country name\n",
    "Happy16['Country'].replace('North Cyprus', 'Cyprus', inplace=True)\n",
    "Happy18['Country'].replace('Northern Cyprus', 'Cyprus', inplace=True)\n",
    "Happy18['Country'].replace('Trinidad & Tobago', 'Trinidad and Tobago', inplace=True)\n",
    "\n",
    "# Assign values based on most plausible region\n",
    "Happy18.loc[Happy18['Country'] == 'Cyprus', ['Region']] = 'Middle East and Northern Africa'\n",
    "Happy18.loc[Happy18['Country'] == 'Trinidad and Tobago', ['Region']] = 'Latin America and Caribbean'\n",
    "Happy18.loc[Happy18['Country'] == 'Lesotho', ['Region']] = 'Sub-Saharan Africa'\n",
    "Happy18.loc[Happy18['Country'] == 'Central African Republic', ['Region']] = 'Sub-Saharan Africa'\n",
    "Happy18.loc[Happy18['Country'] == 'Mozambique', ['Region']] = 'Sub-Saharan Africa'\n",
    "\n",
    "# Check columns for missing values\n",
    "Happy18.isnull().sum(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tables to csv files for easy reuse\n",
    "Happy16.to_csv('HappinessScores16.csv')\n",
    "Happy18.to_csv('HappinessScores18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Begin Pre Processing the GDP pre Capita Scores CSV#########\n",
    "# Read and format csv file\n",
    "gdpCap = pd.read_csv('gdpCap.csv')\n",
    "newGDP =  gdpCap[['Country Name', '2016', '2018']].copy() # Create copy of the table with the relevant columns\n",
    "newGDP.columns = ['Country', 'gdpCap16', 'gdpCap18'] # Change column names to make them consistent\n",
    "#gdpCap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check country name discrepancies\n",
    "set(Happy16['Country']) - set(newGDP['Country'])\n",
    "set(Happy18['Country']) - set(newGDP['Country'])\n",
    "\n",
    "# Map country names to Happiness Score Country names where possible\n",
    "newGDP['Country'].replace('Congo, Rep.', 'Congo (Brazzaville)', inplace=True)\n",
    "newGDP['Country'].replace('North Macedonia', 'Macedonia', inplace=True)\n",
    "newGDP['Country'].replace('Yemen, Rep.', 'Yemen', inplace=True)\n",
    "newGDP['Country'].replace('Slovak Republic', 'Slovakia', inplace=True)\n",
    "newGDP['Country'].replace(\"Cote d'Ivoire\", 'Ivory Coast', inplace=True)\n",
    "newGDP['Country'].replace('Kyrgyz Republic', 'Kyrgyzstan', inplace=True)\n",
    "newGDP['Country'].replace('Hong Kong SAR, China',  'Hong Kong', inplace=True)\n",
    "newGDP['Country'].replace('Venezuela, RB', 'Russia', inplace=True)\n",
    "newGDP['Country'].replace('Congo, Dem. Rep.', 'Congo (Kinshasa)', inplace=True)\n",
    "newGDP['Country'].replace('Korea, Rep.', 'South Korea', inplace=True)\n",
    "newGDP['Country'].replace('Syrian Arab Republic', 'Syria', inplace=True)\n",
    "newGDP['Country'].replace('Lao PDR', 'Laos', inplace=True)\n",
    "newGDP['Country'].replace('Egypt, Arab Rep.', 'Egypt', inplace=True)\n",
    "newGDP['Country'].replace('Cyprus', 'North Cyprus', inplace=True)\n",
    "newGDP['Country'].replace('Russian Federation', 'Russia', inplace=True)\n",
    "\n",
    "# Check Country names have updated correctly\n",
    "set(Happy16['Country']) - set(newGDP['Country'])\n",
    "set(Happy18['Country']) - set(newGDP['Country'])\n",
    "\n",
    "# Copy newGDP table to CSV\n",
    "newGDP.to_csv('GDP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Country            0\nRegion             0\nHappiness Score    0\ngdpCap18           0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 816
    }
   ],
   "source": [
    "# Perform inner join merge between newGDP and Happiness table to drop any remaining outstanding values\n",
    "gdpHappy16 = pd.merge(Happy16, newGDP[['Country', 'gdpCap16']], on=['Country'], how='inner')\n",
    "gdpHappy18 = pd.merge(Happy18, newGDP[['Country', 'gdpCap18']], on=['Country'], how='inner')\n",
    "\n",
    "# Check for nulls\n",
    "gdpHappy16[gdpHappy16.isna().any(axis=1)]\n",
    "gdpHappy18[gdpHappy18.isna().any(axis=1)]\n",
    "\n",
    "# Drop null rows\n",
    "gdpHappy16 = gdpHappy16.dropna()\n",
    "gdpHappy18 = gdpHappy18.dropna()\n",
    "\n",
    "# Check for nulls\n",
    "gdpHappy16.isnull().sum(axis = 0)\n",
    "gdpHappy18.isnull().sum(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Begin Pre Processing the EPI Scores CSV#########\n",
    "epi16 = pd.read_csv('EPI 2016 Scores.csv')\n",
    "epi18 = pd.read_csv('EPI 2018 Scores.csv')\n",
    "#epi16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify null values in the Data to choose which columns to drop\n",
    "epi16.isnull().sum(axis=0)\n",
    "epi18.isnull().sum(axis=0)\n",
    "\n",
    "# Check for 0 values in the dataset\n",
    "epi16.isna().sum(axis=0)\n",
    "epi18.isna().sum(axis=0)\n",
    "\n",
    "# Average data between AIR.current and APE.current as EH - Air Quality encompasses both\n",
    "epi18['AIRQ.current'] = epi18[['AIR.current', 'APE.current']].mean(axis=1)\n",
    "\n",
    "# Extract useful Data to new table\n",
    "Epi16 =  epi16[['Country', 'EH - Air Quality', 'EV - Biodiversity and Habitat', 'EH - Water and Sanitation', 'EV - Water Resources']].copy()\n",
    "Epi18 =  epi18[['country', 'AIRQ.current', 'BDH.current', 'H2O.current', 'WRS.current']].copy()\n",
    "\n",
    "# Rename table column headers for consistency\n",
    "Epi16.columns = ['Country', 'Air Quality', 'Biodiversity', 'Water Sanitation', 'Water Resource']\n",
    "Epi18.columns = ['Country', 'Air Quality', 'Biodiversity', 'Water Sanitation', 'Water Resource']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'Hong Kong', 'Puerto Rico', 'Vietnam', 'United States', 'Kyrgyzstan', 'Congo (Brazzaville)', 'Kosovo', 'Congo (Kinshasa)', 'Ivory Coast'}\n{'Hong Kong', 'Yemen', 'Vietnam', 'United States', 'Congo (Brazzaville)', 'Somalia', 'Kosovo', 'Congo (Kinshasa)'}\n"
    }
   ],
   "source": [
    "# Compare country sets to match up countries\n",
    "print(set(gdpHappy16['Country']) - set(Epi16['Country']))\n",
    "print(set(gdpHappy18['Country']) - set(Epi18['Country']))\n",
    "\n",
    "# Map countries on the EPI16 reports\n",
    "Epi16['Country'].replace('Congo', 'Congo (Brazzaville)', inplace=True)\n",
    "Epi16['Country'].replace('Viet Nam', 'Vietnam', inplace=True)\n",
    "Epi16['Country'].replace('United States of America', 'United States', inplace=True)\n",
    "Epi16['Country'].replace(\"Cote d'Ivoire\", 'Ivory Coast', inplace=True)\n",
    "Epi16['Country'].replace('Dem. Rep. Congo', 'Congo (Kinshasa)', inplace=True)\n",
    "Epi16['Country'].replace('Kyrgyz Republic', 'Kyrgyzstan', inplace=True)\n",
    "\n",
    "# Map countries on the EPI18 reports\n",
    "Epi18['Country'].replace('Republic of Congo', 'Congo (Brazzaville)', inplace=True)\n",
    "Epi18['Country'].replace('Viet Nam', 'Vietnam', inplace=True)\n",
    "Epi18['Country'].replace('United States of America', 'United States', inplace=True)\n",
    "Epi18['Country'].replace('Dem. Rep. Congo', 'Congo (Kinshasa)', inplace=True)\n",
    "Epi18['Country'].replace('Kyrgyz Republic', 'Kyrgyzstan', inplace=True)\n",
    "\n",
    "# Perform inner merge to add EPI data to Happiness scores\n",
    "gdpEpiHappy16 = pd.merge(gdpHappy16, Epi16, on=['Country'], how='inner')\n",
    "gdpEpiHappy18 = pd.merge(gdpHappy18, Epi18, on=['Country'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to csv\n",
    "gdpEpiHappy16.to_csv('test16.csv')\n",
    "gdpEpiHappy18.to_csv('test18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              Location  2016  2018\n0          Afghanistan  0.29  0.29\n1              Albania  1.60  1.64\n2              Algeria  3.85  3.94\n3               Angola  1.16  0.98\n4  Antigua and Barbuda  6.26  6.23",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Location</th>\n      <th>2016</th>\n      <th>2018</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>0.29</td>\n      <td>0.29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>1.60</td>\n      <td>1.64</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algeria</td>\n      <td>3.85</td>\n      <td>3.94</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Angola</td>\n      <td>1.16</td>\n      <td>0.98</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Antigua and Barbuda</td>\n      <td>6.26</td>\n      <td>6.23</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 821
    }
   ],
   "source": [
    "#########Add CO2 data##########\n",
    "# Measured in tons of CO2 per capita\n",
    "# Data got from https://knoema.com/atlas/ranks/CO2-emissions-per-capita?action=export&gadget=tranking-container\n",
    "# Extra values input manually from https://knoema.com/EDGARED2019/global-ghg-and-co2-emissions?location=1000500&indicator=1000070&type=1000140&utm_source=datafinder&utm_medium=excel&utm_campaign=sourcelink&frequency=A&lastUpdated=1585308536760#\n",
    "co2 = pd.read_csv('CO2data.csv')\n",
    "co2Data =  co2[['Location', '2016', '2018']].copy()\n",
    "co2Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'Congo (Kinshasa)', 'Congo (Brazzaville)', 'Myanmar'}\n{'Congo (Kinshasa)', 'Congo (Brazzaville)', 'Myanmar'}\n"
    }
   ],
   "source": [
    "# Check unmapped countries\n",
    "print(set(gdpEpiHappy16['Country']) - set(co2Data['Location']))\n",
    "print(set(gdpEpiHappy18['Country']) - set(co2Data['Location']))\n",
    "\n",
    "# Map countries\n",
    "co2Data['Location'].replace('Congo', 'Congo (Brazzaville)', inplace=True)\n",
    "co2Data['Location'].replace('Democratic Republic of the Congo', 'Congo (Kinshasa)', inplace=True)\n",
    "co2Data['Location'].replace('Myanmar/Burma', 'Myanmar', inplace=True)\n",
    "co2Data['Location'].replace('North Macedonia', 'Macedonia', inplace=True)\n",
    "\n",
    "# Change column names\n",
    "co2Data.columns = ['Country', '2016', '2018']\n",
    "\n",
    "# Merge CO2 Data\n",
    "final16= pd.merge(gdpEpiHappy16, co2Data[['Country', '2016']], on=['Country'], how='inner')\n",
    "final18= pd.merge(gdpEpiHappy18, co2Data[['Country', '2018']], on=['Country'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Country             0\nRegion              0\nGDP per Capita      0\nCO2 per Capita      0\nAir Quality         0\nBiodiversity        0\nWater Sanitation    0\nHappiness Score     0\ndtype: int64\nCountry             0\nRegion              0\nGDP per Capita      0\nCO2 per Capita      0\nAir Quality         0\nBiodiversity        0\nWater Sanitation    0\nHappiness Score     0\ndtype: int64\n"
    }
   ],
   "source": [
    "# Final table format\n",
    "final16 = final16.reindex(columns=['Country', 'Region', 'gdpCap16', '2016', 'Air Quality', 'Biodiversity', 'Water Sanitation', 'Water Resource', 'Happiness Score'])\n",
    "final18 = final18.reindex(columns=['Country', 'Region', 'gdpCap18', '2018', 'Air Quality', 'Biodiversity', 'Water Sanitation', 'Water Resource', 'Happiness Score'])\n",
    "final16.columns = ['Country', 'Region', 'GDP per Capita', 'CO2 per Capita', 'Air Quality', 'Biodiversity', 'Water Sanitation', 'Water Resource', 'Happiness Score']\n",
    "final18.columns = ['Country', 'Region', 'GDP per Capita', 'CO2 per Capita', 'Air Quality', 'Biodiversity', 'Water Sanitation', 'Water Resource', 'Happiness Score']\n",
    "\n",
    "# Too many 0 values in the Water Resource column so needs to be deleted\n",
    "final16 = final16.drop(['Water Resource'], axis=1)\n",
    "final18 = final18.drop(['Water Resource'], axis=1)\n",
    "\n",
    "# Check for nulls\n",
    "print(final16.isna().sum(axis = 0))\n",
    "print(final18.isna().sum(axis = 0))\n",
    "\n",
    "# Drops any duplicates countries\n",
    "final16.drop_duplicates(subset = 'Country', keep=False, inplace=True)\n",
    "final18.drop_duplicates(subset = 'Country', keep=False, inplace=True)\n",
    "\n",
    "# Replace 0 value\n",
    "final18['Water Sanitation'].replace(0, 0.001, inplace=True)\n",
    "\n",
    "# Get final table shape\n",
    "final16.describe()\n",
    "final18.describe()\n",
    "\n",
    "# Create total table\n",
    "finalTotal = final16.append(final18, ignore_index=True)\n",
    "\n",
    "# Export to csv\n",
    "final16.to_csv('final16.csv')\n",
    "final18.to_csv('final18.csv')\n",
    "finalTotal.to_csv('finalTotal.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normal16 = final16.copy()\n",
    "normal18 = final18.copy()\n",
    "normalTotal = finalTotal.copy()\n",
    "\n",
    "# Scale data using MinMaxScaler funcion\n",
    "scaler = MinMaxScaler()\n",
    "def MinMax(df):\n",
    "    for col in df.columns:\n",
    "        if df[f'{col}'].dtype != 'object':\n",
    "            df[[f'{col}']] = scaler.fit_transform(df[[f'{col}']])\n",
    "\n",
    "MinMax(normal16)\n",
    "MinMax(normal18)\n",
    "MinMax(normalTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Normalised data as CSV\n",
    "normal16.to_csv('normal16.csv')\n",
    "normal18.to_csv('normal18.csv')\n",
    "normalTotal.to_csv('normalTotal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create QQplot for each column\n",
    "def QQPlot(df):\n",
    "    for col in df.columns:\n",
    "        if df[f'{col}'].dtype != 'object':\n",
    "            sm.qqplot(df[f'{col}'], line='s', label=f'{col}')\n",
    "            pylab.legend()\n",
    "            pylab.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bithappyconda049ad4268bfd487294cb0ae01474c274",
   "display_name": "Python 3.6.10 64-bit ('Happy': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}